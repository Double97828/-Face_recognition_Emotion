{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(1./255)\n",
    "val_gen = ImageDataGenerator(1./255)\n",
    "train_data = train_gen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_data = val_gen.flow_from_directory(\n",
    "        'test',\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "448/448 [==============================] - 1135s 3s/step - loss: 1.8161 - accuracy: 0.2497 - val_loss: 1.7405 - val_accuracy: 0.3125\n",
      "Epoch 2/20\n",
      "448/448 [==============================] - 1198s 3s/step - loss: 1.5815 - accuracy: 0.3675 - val_loss: 1.4970 - val_accuracy: 0.4114\n",
      "Epoch 3/20\n",
      "448/448 [==============================] - 1282s 3s/step - loss: 1.3984 - accuracy: 0.4373 - val_loss: 1.3271 - val_accuracy: 0.4806\n",
      "Epoch 4/20\n",
      "448/448 [==============================] - 1294s 3s/step - loss: 1.2726 - accuracy: 0.5034 - val_loss: 1.2316 - val_accuracy: 0.5220\n",
      "Epoch 5/20\n",
      "448/448 [==============================] - 1199s 3s/step - loss: 1.1632 - accuracy: 0.5479 - val_loss: 1.2028 - val_accuracy: 0.5346\n",
      "Epoch 6/20\n",
      "448/448 [==============================] - 1174s 3s/step - loss: 1.0711 - accuracy: 0.5903 - val_loss: 1.1497 - val_accuracy: 0.5600\n",
      "Epoch 7/20\n",
      "448/448 [==============================] - 1202s 3s/step - loss: 0.9708 - accuracy: 0.6371 - val_loss: 1.1604 - val_accuracy: 0.5674\n",
      "Epoch 8/20\n",
      "448/448 [==============================] - 1592s 4s/step - loss: 0.8608 - accuracy: 0.6785 - val_loss: 1.1625 - val_accuracy: 0.5748\n",
      "Epoch 9/20\n",
      "448/448 [==============================] - 1267s 3s/step - loss: 0.7457 - accuracy: 0.7270 - val_loss: 1.2559 - val_accuracy: 0.5727\n",
      "Epoch 10/20\n",
      "448/448 [==============================] - 1247s 3s/step - loss: 0.6257 - accuracy: 0.7774 - val_loss: 1.2665 - val_accuracy: 0.5841\n",
      "Epoch 11/20\n",
      "448/448 [==============================] - 1236s 3s/step - loss: 0.5119 - accuracy: 0.8198 - val_loss: 1.3501 - val_accuracy: 0.5855\n",
      "Epoch 12/20\n",
      "448/448 [==============================] - 1214s 3s/step - loss: 0.4146 - accuracy: 0.8555 - val_loss: 1.4444 - val_accuracy: 0.5823\n",
      "Epoch 13/20\n",
      "448/448 [==============================] - 1246s 3s/step - loss: 0.3380 - accuracy: 0.8866 - val_loss: 1.6385 - val_accuracy: 0.5910\n",
      "Epoch 14/20\n",
      "448/448 [==============================] - 1163s 3s/step - loss: 0.2719 - accuracy: 0.9094 - val_loss: 1.6399 - val_accuracy: 0.5872\n",
      "Epoch 15/20\n",
      "448/448 [==============================] - 1132s 3s/step - loss: 0.2228 - accuracy: 0.9277 - val_loss: 1.7172 - val_accuracy: 0.5829\n",
      "Epoch 16/20\n",
      "448/448 [==============================] - 1121s 3s/step - loss: 0.1988 - accuracy: 0.9335 - val_loss: 1.8416 - val_accuracy: 0.5875\n",
      "Epoch 17/20\n",
      "448/448 [==============================] - 1117s 2s/step - loss: 0.1727 - accuracy: 0.9437 - val_loss: 1.9349 - val_accuracy: 0.5911\n",
      "Epoch 18/20\n",
      "448/448 [==============================] - 1123s 3s/step - loss: 0.1543 - accuracy: 0.9497 - val_loss: 2.1004 - val_accuracy: 0.5893\n",
      "Epoch 19/20\n",
      "448/448 [==============================] - 1087s 2s/step - loss: 0.1344 - accuracy: 0.9572 - val_loss: 2.2831 - val_accuracy: 0.5780\n",
      "Epoch 20/20\n",
      "448/448 [==============================] - 1103s 2s/step - loss: 0.1239 - accuracy: 0.9605 - val_loss: 2.1223 - val_accuracy: 0.5910\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(48,48,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(Dense(units=1024,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=3e-4),metrics=['accuracy'])\n",
    "\n",
    "model_info = model.fit_generator(\n",
    "        train_data,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=20,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=7178 // 64)\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
